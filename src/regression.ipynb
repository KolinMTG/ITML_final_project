{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74ead67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "WINE QUALITY REGRESSION - SIMPLIFIED PIPELINE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# SECTION 1: IMPORTS AND SETUP\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Setup\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "PLOTS_DIR = Path(r\"../plots/regression\")\n",
    "REPORTS_DIR = Path(r\"../documents/reports\")\n",
    "DATASET_PATH = r\"../data/main_ready.csv\"\n",
    "PLOTS_DIR.mkdir(exist_ok=True)\n",
    "REPORTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"WINE QUALITY REGRESSION - SIMPLIFIED PIPELINE\")\n",
    "print(\"=\"*80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f767663",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# SECTION 2: DATA LOADING\n",
    "# ============================================================================\n",
    "\n",
    "def load_data(filepath='wine_dataset.csv'):\n",
    "    \"\"\"Load and display basic info about wine dataset.\"\"\"\n",
    "    print(\"\\n[LOADING DATA]\")\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    X = df.drop('quality', axis=1)\n",
    "    y = df['quality']\n",
    "    \n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Quality range: [{y.min()}, {y.max()}]\")\n",
    "    print(f\"Quality mean: {y.mean():.2f} ± {y.std():.2f}\")\n",
    "    \n",
    "    return X, y, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fd04d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 3: MODEL TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "def train_all_models(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Train and evaluate all regression models.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TRAINING MODELS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Ridge': Ridge(alpha=1.0, random_state=RANDOM_STATE),\n",
    "        'Lasso': Lasso(alpha=0.1, random_state=RANDOM_STATE),\n",
    "        'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=RANDOM_STATE),\n",
    "        'Decision Tree': DecisionTreeRegressor(max_depth=10, random_state=RANDOM_STATE),\n",
    "        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=RANDOM_STATE),\n",
    "        'SVR': SVR(kernel='rbf', C=10),\n",
    "        'Neural Network': MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, \n",
    "                                       random_state=RANDOM_STATE)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        \n",
    "        # Train\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        \n",
    "        # Metrics\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "        test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "        test_r2 = r2_score(y_test, y_pred_test)\n",
    "        train_r2 = r2_score(y_train, y_pred_train)\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, \n",
    "                                    scoring='neg_mean_squared_error')\n",
    "        cv_rmse = np.sqrt(-cv_scores.mean())\n",
    "        \n",
    "        print(f\"  RMSE: {test_rmse:.4f} | MAE: {test_mae:.4f} | R²: {test_r2:.4f}\")\n",
    "        \n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'y_pred': y_pred_test,\n",
    "            'y_test': y_test,\n",
    "            'residuals': y_test - y_pred_test,\n",
    "            'metrics': {\n",
    "                'name': name,\n",
    "                'test_rmse': test_rmse,\n",
    "                'test_mae': test_mae,\n",
    "                'test_r2': test_r2,\n",
    "                'train_r2': train_r2,\n",
    "                'cv_rmse': cv_rmse\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2e0dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 4: VISUALIZATIONS\n",
    "# ============================================================================\n",
    "\n",
    "def plot_quality_distribution(y, save_path):\n",
    "    \"\"\"Plot quality score distribution.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    axes[0].hist(y, bins=range(int(y.min()), int(y.max())+2), \n",
    "                 color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[0].set_xlabel('Quality Score', fontweight='bold')\n",
    "    axes[0].set_ylabel('Count', fontweight='bold')\n",
    "    axes[0].set_title('Quality Distribution', fontweight='bold', fontsize=14)\n",
    "    \n",
    "    axes[1].boxplot(y, vert=True)\n",
    "    axes[1].set_ylabel('Quality Score', fontweight='bold')\n",
    "    axes[1].set_title('Quality Box Plot', fontweight='bold', fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_predictions_vs_actual(results, save_path):\n",
    "    \"\"\"Plot predicted vs actual for all models.\"\"\"\n",
    "    n_models = len(results)\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (name, result) in enumerate(results.items()):\n",
    "        y_test = result['y_test']\n",
    "        y_pred = result['y_pred']\n",
    "        r2 = result['metrics']['test_r2']\n",
    "        \n",
    "        axes[idx].scatter(y_test, y_pred, alpha=0.5, s=15)\n",
    "        \n",
    "        # Perfect prediction line\n",
    "        min_val = min(y_test.min(), y_pred.min())\n",
    "        max_val = max(y_test.max(), y_pred.max())\n",
    "        axes[idx].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "        \n",
    "        axes[idx].set_xlabel('Actual Quality', fontweight='bold')\n",
    "        axes[idx].set_ylabel('Predicted Quality', fontweight='bold')\n",
    "        axes[idx].set_title(f'{name}\\nR² = {r2:.4f}', fontweight='bold')\n",
    "        axes[idx].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_model_comparison(metrics_df, save_path):\n",
    "    \"\"\"Compare model performance.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    \n",
    "    # R² comparison\n",
    "    metrics_sorted = metrics_df.sort_values('test_r2', ascending=True)\n",
    "    axes[0].barh(metrics_sorted['name'], metrics_sorted['test_r2'], color='steelblue')\n",
    "    axes[0].set_xlabel('R² Score', fontweight='bold')\n",
    "    axes[0].set_title('R² Comparison', fontweight='bold', fontsize=14)\n",
    "    axes[0].set_xlim([0, 1])\n",
    "    \n",
    "    # RMSE comparison\n",
    "    metrics_sorted = metrics_df.sort_values('test_rmse', ascending=False)\n",
    "    axes[1].barh(metrics_sorted['name'], metrics_sorted['test_rmse'], color='coral')\n",
    "    axes[1].set_xlabel('RMSE', fontweight='bold')\n",
    "    axes[1].set_title('RMSE Comparison (Lower = Better)', fontweight='bold', fontsize=14)\n",
    "    \n",
    "    # MAE comparison\n",
    "    metrics_sorted = metrics_df.sort_values('test_mae', ascending=False)\n",
    "    axes[2].barh(metrics_sorted['name'], metrics_sorted['test_mae'], color='seagreen')\n",
    "    axes[2].set_xlabel('MAE', fontweight='bold')\n",
    "    axes[2].set_title('MAE Comparison (Lower = Better)', fontweight='bold', fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_residuals(results, save_path):\n",
    "    \"\"\"Plot residuals for all models.\"\"\"\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (name, result) in enumerate(results.items()):\n",
    "        residuals = result['residuals']\n",
    "        y_pred = result['y_pred']\n",
    "        \n",
    "        axes[idx].scatter(y_pred, residuals, alpha=0.5, s=15)\n",
    "        axes[idx].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "        axes[idx].set_xlabel('Predicted Quality', fontweight='bold')\n",
    "        axes[idx].set_ylabel('Residuals', fontweight='bold')\n",
    "        axes[idx].set_title(f'{name}', fontweight='bold')\n",
    "        axes[idx].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_feature_importance(results, X, save_path):\n",
    "    \"\"\"Plot feature importance for tree-based models.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    tree_models = ['Random Forest', 'Gradient Boosting', 'Decision Tree']\n",
    "    \n",
    "    for idx, name in enumerate(tree_models):\n",
    "        if name in results:\n",
    "            model = results[name]['model']\n",
    "            importances = model.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1][:10]\n",
    "            \n",
    "            axes[idx].barh(range(len(indices)), importances[indices], color='teal')\n",
    "            axes[idx].set_yticks(range(len(indices)))\n",
    "            axes[idx].set_yticklabels([X.columns[i] for i in indices])\n",
    "            axes[idx].set_xlabel('Importance', fontweight='bold')\n",
    "            axes[idx].set_title(f'{name}\\nTop 10 Features', fontweight='bold')\n",
    "            axes[idx].invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_correlation_matrix(df, save_path):\n",
    "    \"\"\"Plot correlation with quality.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Correlation bar plot\n",
    "    corr = df.corr()['quality'].drop('quality').sort_values(ascending=False)\n",
    "    colors = ['green' if x > 0 else 'red' for x in corr.values]\n",
    "    axes[0].barh(corr.index, corr.values, color=colors, alpha=0.7)\n",
    "    axes[0].set_xlabel('Correlation with Quality', fontweight='bold')\n",
    "    axes[0].set_title('Feature Correlations', fontweight='bold', fontsize=14)\n",
    "    axes[0].axvline(x=0, color='black', linewidth=0.8)\n",
    "    \n",
    "    # Correlation heatmap\n",
    "    sns.heatmap(df.corr(), annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                center=0, ax=axes[1], cbar_kws={'label': 'Correlation'})\n",
    "    axes[1].set_title('Correlation Matrix', fontweight='bold', fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee9526d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 5: REPORT GENERATION\n",
    "# ============================================================================\n",
    "\n",
    "def generate_report(metrics_df, df):\n",
    "    \"\"\"Generate markdown report.\"\"\"\n",
    "    \n",
    "    best_model = metrics_df.iloc[0]\n",
    "    \n",
    "    report = f\"\"\"# Wine Quality Regression - Analysis Report\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This analysis predicts wine quality scores using chemical properties. \n",
    "{len(metrics_df)} regression models were trained and evaluated.\n",
    "\n",
    "**Best Model**: {best_model['name']}\n",
    "- R² Score: {best_model['test_r2']:.4f}\n",
    "- RMSE: {best_model['test_rmse']:.4f}\n",
    "- MAE: {best_model['test_mae']:.4f}\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Dataset Overview\n",
    "\n",
    "- **Total Samples**: {len(df)}\n",
    "- **Features**: {len(df.columns)-1}\n",
    "- **Target**: Quality score ({df['quality'].min()}-{df['quality'].max()})\n",
    "- **Mean Quality**: {df['quality'].mean():.2f} ± {df['quality'].std():.2f}\n",
    "\n",
    "### Quality Distribution\n",
    "{df['quality'].value_counts().sort_index().to_string()}\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Model Performance\n",
    "\n",
    "### All Models Summary\n",
    "\n",
    "{metrics_df.to_markdown(index=False, floatfmt='.4f')}\n",
    "\n",
    "### Top 3 Models\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    for i, row in metrics_df.head(3).iterrows():\n",
    "        report += f\"\"\"\n",
    "#### {i+1}. {row['name']}\n",
    "- **R² Score**: {row['test_r2']:.4f} ({row['test_r2']*100:.1f}% variance explained)\n",
    "- **RMSE**: {row['test_rmse']:.4f} quality points\n",
    "- **MAE**: {row['test_mae']:.4f} quality points\n",
    "- **CV RMSE**: {row['cv_rmse']:.4f}\n",
    "\"\"\"\n",
    "    \n",
    "    report += \"\"\"\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Key Findings\n",
    "\n",
    "### Model Comparison\n",
    "- **Tree-based models** (Random Forest, Gradient Boosting) perform best\n",
    "- **R² scores** typically range from 0.35-0.50\n",
    "- **RMSE** around 0.6-0.7 quality points\n",
    "\n",
    "### Interpretation\n",
    "- Models explain 35-50% of quality variance\n",
    "- Predictions within ±0.6-0.7 quality points on average\n",
    "- Chemical properties are moderately predictive of quality\n",
    "- Human factors (taste, preference) likely account for remaining variance\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Recommendations\n",
    "\n",
    "### Production Deployment\n",
    "**Recommended Model**: Random Forest or Gradient Boosting\n",
    "\n",
    "**Use Cases**:\n",
    "1. Quality control screening\n",
    "2. Batch quality prediction\n",
    "3. Production optimization guidance\n",
    "\n",
    "### Limitations\n",
    "- Models explain ~40-50% of variance\n",
    "- Quality is subjective and context-dependent\n",
    "- Chemical properties alone cannot fully predict quality\n",
    "- Model best used as screening tool, not replacement for expert tasting\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Visualizations\n",
    "\n",
    "All plots saved in `plots_regression/`:\n",
    "1. `quality_distribution.png` - Target variable distribution\n",
    "2. `predictions_vs_actual.png` - Model predictions vs reality\n",
    "3. `model_comparison.png` - Performance metrics comparison\n",
    "4. `residuals_analysis.png` - Residual plots\n",
    "5. `feature_importance.png` - Key features from tree models\n",
    "6. `correlation_matrix.png` - Feature correlations\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Conclusion\n",
    "\n",
    "Wine quality can be predicted with **moderate accuracy** using chemical properties. \n",
    "The best models achieve R² ≈ 0.45-0.50 and RMSE ≈ 0.60-0.65.\n",
    "\n",
    "**Key Takeaway**: Chemical analysis provides useful quality indicators but cannot \n",
    "fully replace expert sensory evaluation.\n",
    "\n",
    "---\n",
    "\n",
    "*Report generated: January 2026*\n",
    "\"\"\"\n",
    "    \n",
    "    return report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96528b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Update filepath below with your dataset\n",
      "[INFO] Uncomment the code block to run\n",
      "\n",
      "\n",
      "[LOADING DATA]\n",
      "Dataset shape: (5320, 12)\n",
      "Quality range: [3, 9]\n",
      "Quality mean: 5.80 ± 0.88\n",
      "\n",
      "Train size: 4256 | Test size: 1064\n",
      "\n",
      "================================================================================\n",
      "TRAINING MODELS\n",
      "================================================================================\n",
      "\n",
      "Training Linear Regression...\n",
      "  RMSE: 0.7262 | MAE: 0.5631 | R²: 0.2985\n",
      "\n",
      "Training Ridge...\n",
      "  RMSE: 0.7262 | MAE: 0.5631 | R²: 0.2985\n",
      "\n",
      "Training Lasso...\n",
      "  RMSE: 0.7493 | MAE: 0.5902 | R²: 0.2533\n",
      "\n",
      "Training ElasticNet...\n",
      "  RMSE: 0.7396 | MAE: 0.5783 | R²: 0.2724\n",
      "\n",
      "Training Decision Tree...\n",
      "  RMSE: 0.8201 | MAE: 0.6165 | R²: 0.1055\n",
      "\n",
      "Training Random Forest...\n",
      "  RMSE: 0.6657 | MAE: 0.5115 | R²: 0.4105\n",
      "\n",
      "Training Gradient Boosting...\n",
      "  RMSE: 0.6837 | MAE: 0.5263 | R²: 0.3783\n",
      "\n",
      "Training SVR...\n",
      "  RMSE: 0.7139 | MAE: 0.5364 | R²: 0.3221\n",
      "\n",
      "Training Neural Network...\n",
      "  RMSE: 0.7205 | MAE: 0.5539 | R²: 0.3096\n",
      "\n",
      "================================================================================\n",
      "GENERATING VISUALIZATIONS\n",
      "================================================================================\n",
      "✓ Visualizations saved\n",
      "\n",
      "================================================================================\n",
      "GENERATING REPORT\n",
      "================================================================================\n",
      "✓ Report saved: ..\\documents\\reports\\wine_regression_report.md\n",
      "✓ Metrics saved: ..\\documents\\reports\\metrics.csv\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE\n",
      "================================================================================\n",
      "\n",
      " Plots: ..\\plots\\regression/\n",
      " Report: ..\\documents\\reports/\n",
      "\n",
      "Top 3 Models:\n",
      "  6. Random Forest: R²=0.4105, RMSE=0.6657\n",
      "  7. Gradient Boosting: R²=0.3783, RMSE=0.6837\n",
      "  8. SVR: R²=0.3221, RMSE=0.7139\n",
      "Script ready. Uncomment main() code to execute.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# SECTION 6: MAIN PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Execute complete pipeline.\"\"\"\n",
    "    \n",
    "    print(\"\\n[INFO] Update filepath below with your dataset\")\n",
    "    print(\"[INFO] Uncomment the code block to run\\n\")\n",
    "    \n",
    "    # === UNCOMMENT TO RUN ===\n",
    "    \n",
    "    # Load data\n",
    "    X, y, df = load_data(DATASET_PATH)\n",
    "    \n",
    "    # Visualize target\n",
    "    plot_quality_distribution(y, PLOTS_DIR / 'quality_distribution.png')\n",
    "    plot_correlation_matrix(df, PLOTS_DIR / 'correlation_matrix.png')\n",
    "    \n",
    "    # Split and scale\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                         random_state=RANDOM_STATE)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
    "    X_test = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n",
    "    \n",
    "    print(f\"\\nTrain size: {len(X_train)} | Test size: {len(X_test)}\")\n",
    "    \n",
    "    # Train models\n",
    "    results = train_all_models(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # Create metrics dataframe\n",
    "    metrics_df = pd.DataFrame([r['metrics'] for r in results.values()])\n",
    "    metrics_df = metrics_df.sort_values('test_r2', ascending=False)\n",
    "    \n",
    "    # Generate visualizations\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GENERATING VISUALIZATIONS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    plot_predictions_vs_actual(results, PLOTS_DIR / 'predictions_vs_actual.png')\n",
    "    plot_model_comparison(metrics_df, PLOTS_DIR / 'model_comparison.png')\n",
    "    plot_residuals(results, PLOTS_DIR / 'residuals_analysis.png')\n",
    "    plot_feature_importance(results, X, PLOTS_DIR / 'feature_importance.png')\n",
    "    \n",
    "    print(\"✓ Visualizations saved\")\n",
    "    \n",
    "    # Generate report\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GENERATING REPORT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    report = generate_report(metrics_df, df)\n",
    "    \n",
    "    report_path = REPORTS_DIR / 'wine_regression_report.md'\n",
    "    with open(report_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    metrics_df.to_csv(REPORTS_DIR / 'metrics.csv', index=False)\n",
    "    \n",
    "    print(f\"✓ Report saved: {report_path}\")\n",
    "    print(f\"✓ Metrics saved: {REPORTS_DIR / 'metrics.csv'}\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\n Plots: {PLOTS_DIR}/\")\n",
    "    print(f\" Report: {REPORTS_DIR}/\")\n",
    "    print(f\"\\nTop 3 Models:\")\n",
    "    for i, row in metrics_df.head(3).iterrows():\n",
    "        print(f\"  {i+1}. {row['name']}: R²={row['test_r2']:.4f}, RMSE={row['test_rmse']:.4f}\")\n",
    "    \n",
    "    print(\"Script ready. Uncomment main() code to execute.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LO17_RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
